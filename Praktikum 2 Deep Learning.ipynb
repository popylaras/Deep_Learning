{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5fc55b",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">KLASIFIKASI 2 KELAS</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aea2ef",
   "metadata": {},
   "source": [
    "### Activation pada Dense\n",
    "\n",
    "Setelah kita melakukan regresi menggunakan activation `relu` dan `linear`, pada pertemuan kali ini, kita akan mencoba melakukan klasifikasi menggunakan Dense dengan 2 jenis activation yang berbeda yaitu\n",
    "\n",
    "1.   `sigmoid`\n",
    "2.   `softmax`\n",
    "\n",
    "Jika `linear` kita pergunakan untuk output yang berupa `float`, maka `sigmoid` dan `softmax` kita pergunakan untuk kasus klasifikasi dengan hasil dalam bentuk persentase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7749f6a5",
   "metadata": {},
   "source": [
    "# Sigmoid\n",
    "\n",
    "`sigmoid` kita pergunakan jika kelas yang kita klasifikasikan/kategorikan hanya berjumlah 2 kelas saja. Istilah lainnya untuk kasus ini adalah kasus biner atau binary. Contohnya, kelas `ya` dan `tidak`, atau kelas `cowok` dan `cewek`, atau kelas `sehat` dan `sakit`, dan seterusnya. Tentu saja, kelas-kelas ini haruslah kita representasikan dalam bentuk `0` dan `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21576bc8",
   "metadata": {},
   "source": [
    "# Persiapan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a3395b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633563</td>\n",
       "      <td>0.357385</td>\n",
       "      <td>-0.503931</td>\n",
       "      <td>0.935066</td>\n",
       "      <td>0.647981</td>\n",
       "      <td>-0.050796</td>\n",
       "      <td>-1.933989</td>\n",
       "      <td>2.081684</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>-0.258298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.283905</td>\n",
       "      <td>1.109459</td>\n",
       "      <td>-0.908953</td>\n",
       "      <td>1.006586</td>\n",
       "      <td>0.492219</td>\n",
       "      <td>1.107295</td>\n",
       "      <td>1.243526</td>\n",
       "      <td>-0.172200</td>\n",
       "      <td>1.150359</td>\n",
       "      <td>0.147744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.966476</td>\n",
       "      <td>-0.593314</td>\n",
       "      <td>0.458020</td>\n",
       "      <td>1.032323</td>\n",
       "      <td>1.283685</td>\n",
       "      <td>-0.317640</td>\n",
       "      <td>1.499045</td>\n",
       "      <td>0.434477</td>\n",
       "      <td>0.423678</td>\n",
       "      <td>1.251380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.429309</td>\n",
       "      <td>-1.306530</td>\n",
       "      <td>-1.869925</td>\n",
       "      <td>3.092164</td>\n",
       "      <td>2.028800</td>\n",
       "      <td>-0.879635</td>\n",
       "      <td>-0.393494</td>\n",
       "      <td>-0.101213</td>\n",
       "      <td>-1.624066</td>\n",
       "      <td>0.443553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.204798</td>\n",
       "      <td>0.078464</td>\n",
       "      <td>0.705181</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.618707</td>\n",
       "      <td>1.534946</td>\n",
       "      <td>-0.302288</td>\n",
       "      <td>2.325055</td>\n",
       "      <td>0.495505</td>\n",
       "      <td>0.538133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-1.606404</td>\n",
       "      <td>0.228927</td>\n",
       "      <td>0.959690</td>\n",
       "      <td>0.145821</td>\n",
       "      <td>0.682755</td>\n",
       "      <td>-0.927143</td>\n",
       "      <td>-0.280438</td>\n",
       "      <td>0.789222</td>\n",
       "      <td>-1.330100</td>\n",
       "      <td>-1.463687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.154048</td>\n",
       "      <td>-0.120265</td>\n",
       "      <td>-0.643621</td>\n",
       "      <td>-0.467386</td>\n",
       "      <td>-0.825604</td>\n",
       "      <td>0.725398</td>\n",
       "      <td>-1.439272</td>\n",
       "      <td>-1.132146</td>\n",
       "      <td>1.511610</td>\n",
       "      <td>-0.114986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.841468</td>\n",
       "      <td>-0.593749</td>\n",
       "      <td>-0.391671</td>\n",
       "      <td>-0.955036</td>\n",
       "      <td>-1.169619</td>\n",
       "      <td>0.683856</td>\n",
       "      <td>-1.629486</td>\n",
       "      <td>0.289335</td>\n",
       "      <td>-0.434358</td>\n",
       "      <td>-1.271335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.080252</td>\n",
       "      <td>-0.607761</td>\n",
       "      <td>-0.488605</td>\n",
       "      <td>-1.338506</td>\n",
       "      <td>-1.605447</td>\n",
       "      <td>-1.689724</td>\n",
       "      <td>0.202908</td>\n",
       "      <td>0.291496</td>\n",
       "      <td>0.827980</td>\n",
       "      <td>-1.069399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-1.205338</td>\n",
       "      <td>-1.719647</td>\n",
       "      <td>0.994358</td>\n",
       "      <td>-2.060993</td>\n",
       "      <td>-1.493417</td>\n",
       "      <td>-0.664010</td>\n",
       "      <td>0.718480</td>\n",
       "      <td>-0.305819</td>\n",
       "      <td>-1.405728</td>\n",
       "      <td>-0.703207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0     0.633563  0.357385 -0.503931  0.935066  0.647981 -0.050796 -1.933989   \n",
       "1     1.283905  1.109459 -0.908953  1.006586  0.492219  1.107295  1.243526   \n",
       "2    -0.966476 -0.593314  0.458020  1.032323  1.283685 -0.317640  1.499045   \n",
       "3     2.429309 -1.306530 -1.869925  3.092164  2.028800 -0.879635 -0.393494   \n",
       "4    -1.204798  0.078464  0.705181  0.224765  0.618707  1.534946 -0.302288   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -1.606404  0.228927  0.959690  0.145821  0.682755 -0.927143 -0.280438   \n",
       "9996  1.154048 -0.120265 -0.643621 -0.467386 -0.825604  0.725398 -1.439272   \n",
       "9997  0.841468 -0.593749 -0.391671 -0.955036 -1.169619  0.683856 -1.629486   \n",
       "9998  1.080252 -0.607761 -0.488605 -1.338506 -1.605447 -1.689724  0.202908   \n",
       "9999 -1.205338 -1.719647  0.994358 -2.060993 -1.493417 -0.664010  0.718480   \n",
       "\n",
       "            x8        x9       x10  y  \n",
       "0     2.081684  0.041266 -0.258298  1  \n",
       "1    -0.172200  1.150359  0.147744  1  \n",
       "2     0.434477  0.423678  1.251380  1  \n",
       "3    -0.101213 -1.624066  0.443553  1  \n",
       "4     2.325055  0.495505  0.538133  0  \n",
       "...        ...       ...       ... ..  \n",
       "9995  0.789222 -1.330100 -1.463687  0  \n",
       "9996 -1.132146  1.511610 -0.114986  0  \n",
       "9997  0.289335 -0.434358 -1.271335  0  \n",
       "9998  0.291496  0.827980 -1.069399  0  \n",
       "9999 -0.305819 -1.405728 -0.703207  0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"C:/Users/LENOVO/Praktikum DL/Praktikum_DL/Pertemuan 2/Dataset/dataset_klasifikasi_biner.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15b84c",
   "metadata": {},
   "source": [
    "# Membagi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a11b1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\users\\lenovo\\anaconda3\\envs\\popy\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in d:\\users\\lenovo\\anaconda3\\envs\\popy\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\users\\lenovo\\anaconda3\\envs\\popy\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\users\\lenovo\\anaconda3\\envs\\popy\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\users\\lenovo\\anaconda3\\envs\\popy\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea14d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (2000, 10), (8000,), (2000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop('y', axis=1).values\n",
    "y = df['y'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df030462",
   "metadata": {},
   "source": [
    "# Membuat Arsitektur Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7b0c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=10, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283f98eb",
   "metadata": {},
   "source": [
    "Kemudian mari kita siapkan JST dengan susunan `32-16-8-4-2` dan `1`. Perhatikan, pada layer terakhir kita beri nilai `Dense`-nya `1` dengan activation `sigmoid`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f988cc1",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6288a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 32)                352       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1065 (4.16 KB)\n",
      "Trainable params: 1065 (4.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640eb39",
   "metadata": {},
   "source": [
    "Untuk kasus klasifikasi biner, kita bisa pergunakan `loss`-nya `binary_crossentropy`. Kemudian, selain `loss`, pada praktikum kali ini kita tambahkan satu lagi variabel `metrics` dengan isian `'accuracy'`, untuk mengetahui seberapa akurat otak kita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370a549",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2f98b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 4s 32ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5188\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4812\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6932 - val_accuracy: 0.4812\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6935 - val_accuracy: 0.4812\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.4812\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6935 - val_accuracy: 0.4812\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6935 - val_accuracy: 0.4812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6935 - val_accuracy: 0.4812\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6934 - val_accuracy: 0.4812\n"
     ]
    }
   ],
   "source": [
    "catatan = model.fit(x_train, y_train, validation_split=0.2, batch_size=256, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64d260",
   "metadata": {},
   "source": [
    "# Plot Performa Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6156c5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(catatan.history['val_accuracy'])), catatan.history['val_accuracy'], label='val_accuracy')\n",
    "plt.plot(range(len(catatan.history['accuracy'])), catatan.history['accuracy'], label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bcc9a6",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7553c1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Accuracy Model :  0.49900001287460327\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print('Accuracy Model : ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67853fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f14cda01",
   "metadata": {},
   "source": [
    "# Prediksi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cd3c1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4969585],\n",
       "       [0.4969585],\n",
       "       [0.4969585],\n",
       "       ...,\n",
       "       [0.4969585],\n",
       "       [0.4969585],\n",
       "       [0.4969585]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf1413",
   "metadata": {},
   "source": [
    "Untuk menormalisasikan ke dalam bentuk `0` dan `1`, maka kita perlu menambahkan baris kode sebagai berikut, yang intinya untuk segala nilai yang di atas $0.5$ akan kita rubah ke `kelas 1` dan untuk segala nilai yang di bawah $0.5$ akan kita rubah ke `kelas 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a572bacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = (pred > 0.5)*1\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262ca0e",
   "metadata": {},
   "source": [
    "# Evaluasi dengan Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "381d28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 998 1002]\n",
      " [   0    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fe331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
